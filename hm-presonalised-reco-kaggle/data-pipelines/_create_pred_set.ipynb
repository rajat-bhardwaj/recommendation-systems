{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bd27a45-081c-4756-abed-2682bfbca977",
   "metadata": {},
   "source": [
    "Generate a prediction dataset to evluate and compare retrieval models\n",
    "\n",
    "### Strategy\n",
    "- Take a sample of customers (0.3) from original validation set (for all 3 strategies)\n",
    "- Use only positive examples i.e. purchase == 1\n",
    "- Use this sample to evaluate Evaluation Metrics such as Hit Rate and NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad2e65-75a0-4876-85af-924659f0defb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d21943-6b5b-4d7f-97e2-a0efaa0835a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option(\"display.max_columns\", 1000)\n",
    "pd.set_option(\"display.max_rows\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ca8ac-e55a-4aa8-a66a-d185ef95961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model_data = Path(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fca735-6a7d-4afe-9212-fc18af210eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_s1 = 'CF_model_input_neucf_S1'\n",
    "folder_s3 = 'CF_model_input_S3'\n",
    "folder_neucf_s3 = 'CF_model_input_neucf_S3'\n",
    "folder_s2 = 'CF_model_input_neucf_S2'\n",
    "frac_cust_pred_ds = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce23173d-642e-40d5-8b5d-1aca8ee1bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_dfs(input_df, frac_):\n",
    "    \"\"\" \"\"\"\n",
    "\n",
    "    unique_custs = input_df.customer_id.drop_duplicates().sample(frac=frac_)\n",
    "    \n",
    "    ## only positive interactions\n",
    "    pd_oos_ranking_eval = (input_df[(input_df.customer_id.isin(unique_custs) & (input_df.purchase==1))]\n",
    "                                 .filter(['customer_id', 'article_id'])\n",
    "                                 .drop_duplicates())\n",
    "    \n",
    "    pd_val_set = input_df[~input_df.customer_id.isin(unique_custs)]\n",
    "\n",
    "    return pd_oos_ranking_eval, pd_val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e29ba4b-97d9-4d8b-8f98-f2b6d0aa840d",
   "metadata": {},
   "source": [
    "## Strategy 3 : Data For CF (with negative examples)\n",
    "\n",
    "Each customer will have `n` negative examples per week. This dataset is created to train the model on a sample week.\n",
    "\n",
    "For aggregated dataset over a period, each customer will have `n * frequency of purchase` negative samples. Rebalance the dataset for use in aggregate mode.\n",
    "\n",
    "- for each year, month and week\n",
    "- aggregate all products and select n random articles/products for each customer\n",
    "- set `purchase` feature as 0\n",
    "\n",
    "Difference between Strategy 3 and Strategy 1:\n",
    "- Strategy three will have random sample taken from activity week. It does not follow the `leave-one-out` policy of NeuMF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f74c99-607d-4f2b-b47c-6d730191cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def get_ds_type(year, week):\n",
    "    \"\"\" \"\"\"\n",
    "    # 2018 week-38 to 2020 Week-28\n",
    "    if year < 2020:\n",
    "        op = 'train'\n",
    "    elif year == 2020 & week < 29:\n",
    "        op = 'train'\n",
    "    else:\n",
    "        op = 'val'\n",
    "\n",
    "    return op\n",
    "\n",
    "def get_eval_set(path_, folder, n_neg, folder_write, frac_):\n",
    "    \"\"\"\n",
    "    generates dataset with positive examples only for ranking based evaluation\n",
    "    Resamples the weekly dataset to contain 30 negative examples\n",
    "    \n",
    "    \"\"\"\n",
    "    file_paths = list((path_/folder).rglob('*.parquet'))\n",
    "    \n",
    "    dfs_train = []\n",
    "    dfs_val = []\n",
    "    \n",
    "    for file in file_paths:\n",
    "        value = file.parts[-1].split('_')[0:2]\n",
    "        res = get_ds_type(int(value[0]), int(value[1]))\n",
    "        if res == 'val':\n",
    "            dfs_val.append(pd.read_parquet(file))\n",
    "        else:\n",
    "            dfs_train.append(pd.read_parquet(file))\n",
    "    \n",
    "    pd_train_stg_three = pd.concat(dfs_train)\n",
    "    pd_val_stg_three = pd.concat(dfs_val)\n",
    "    \n",
    "    dfs_train.clear(), dfs_val.clear()\n",
    "    \n",
    "    pd_custs_oos_ranking_eval, pd_validation_set = get_filtered_dfs(pd_val_stg_three, frac_)\n",
    "    \n",
    "    ## only positive interactions\n",
    "    print(pd_train_stg_three.customer_id.nunique(), \n",
    "          pd_val_stg_three.customer_id.nunique(),\n",
    "          pd_custs_oos_ranking_eval.shape, \n",
    "          pd_validation_set.customer_id.nunique())\n",
    "    \n",
    "    ## since strategy three is weekly `n` negative samples. \n",
    "    ## therefore the total number of negatives can be larger than `n`\n",
    "    ## if the customers is active for more than 2 weeeks. Therefore resampling the negatives to `n`\n",
    "    positives = pd_validation_set[pd_validation_set.purchase == 1]\n",
    "    negatives = pd_validation_set[pd_validation_set.purchase == 0]\n",
    "    \n",
    "    groups_ = negatives.groupby(['customer_id'])\n",
    "    \n",
    "    df_list = []\n",
    "    for grp in tqdm(groups_):\n",
    "        df_list.append([grp[0], grp[1].article_id.sample(n=n_neg)])\n",
    "    \n",
    "    test_ = pd.DataFrame(df_list, columns=['customer_id', 'article_id'])\n",
    "    df_list.clear()\n",
    "\n",
    "    test_ = test_.explode(['article_id'])\n",
    "    test_['purchase'] = 0\n",
    "    \n",
    "    assert int(test_.shape[0]/n_neg) ==  pd_validation_set.customer_id.nunique()\n",
    "\n",
    "    validation = pd.concat([positives, test_]).astype('int32')\n",
    "\n",
    "    pd_val_stg_three.to_parquet(path_/folder_write/'val_ds_stg_3.parquet')\n",
    "    validation.to_parquet(path_/folder_write/'val_ds_sample_stg_3.parquet')\n",
    "    pd_train_stg_three.to_parquet(path_/folder_write/'train_ds_stg_3.parquet')\n",
    "    pd_custs_oos_ranking_eval.to_parquet(path_/'evaluation_set_stg_3.parquet')\n",
    "    \n",
    "\n",
    "get_eval_set(path_model_data, folder_s3, 30, folder_neucf_s3, frac_cust_pred_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f802c-740f-47c0-a942-c8e211f21ae9",
   "metadata": {},
   "source": [
    "## Strategy ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cac2f1a-b668-40df-9812-08bc5924f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "val_stg_one = pd.read_parquet(path_model_data / folder_s1 / 'val_ds_stg_1.parquet')\n",
    "pd_ranking_eval, pd_val = get_filtered_dfs(val_stg_one, frac_cust_pred_ds)\n",
    "\n",
    "print(val_stg_one.customer_id.nunique(), pd_ranking_eval.shape, pd_val.customer_id.nunique())\n",
    "\n",
    "pd_ranking_eval.to_parquet(path_model_data / 'evaluation_set_stg_1.parquet')\n",
    "pd_val.to_parquet(path_model_data / folder_s1 / 'val_ds_sample_stg_1.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5063afd0-b189-4562-8cfb-8c33b9347b06",
   "metadata": {},
   "source": [
    "## Strategy Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e02eba-0b7b-4156-a15c-9ee0e508d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "val_stg_two = pd.read_parquet(path_model_data / folder_s2 / 'val_ds_stg_2.parquet')\n",
    "pd_ranking_eval, pd_val = get_filtered_dfs(val_stg_two, frac_cust_pred_ds)\n",
    "\n",
    "print(val_stg_two.customer_id.nunique(), pd_ranking_eval.shape, pd_val.customer_id.nunique())\n",
    "\n",
    "pd_ranking_eval.to_parquet(path_model_data / 'evaluation_set_stg_2.parquet')\n",
    "pd_val.to_parquet(path_model_data / folder_s2 / 'val_ds_sample_stg_2.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8cc11-98a7-498f-8d69-ccd3e60efb4a",
   "metadata": {},
   "source": [
    "## Verify the negative example in strategy one are different than strategy two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30d43d3-ec90-411c-b489-49f171c642bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_prod_one = val_stg_one[(val_stg_one.customer_id==10) & (val_stg_one.purchase==0)].article_id\n",
    "sample_prod_two = val_stg_two[(val_stg_two.customer_id==10) & (val_stg_two.purchase==0)].article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e061fb58-802d-4206-9cd9-4a3bb8c122d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.isin(sample_prod_one, sample_prod_two)\n",
    "sample_prod_one[~mask].shape"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-gpu.m113",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-gpu:m113"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
